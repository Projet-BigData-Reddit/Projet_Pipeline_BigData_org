""""Best command """""""

/opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --files config.py \
  --conf spark.dynamicAllocation.enabled=false \
  /opt/spark/work-dir/run.py

#cassandra sur docker
docker exec -it cassandra cqlsh -e "SELECT * FROM reddit_db.viral_posts;"

#mongodb Local 
mongosh "mongodb://monAdmin:motDePasseUltraSecret@127.0.0.1:27017/reddit_backup?authSource=admin"
db.viral_posts_fallback.find().sort({_id: -1}).limit(5)


#partie airflow 
#lancer postgres :
 docker compose up airflow-postgres -d

#Réinitialiser complètement la base de données Airflow   : 
docker compose run --rm airflow-webserver airflow db reset

#Créer l’utilisateur admin pour l’interface web Airflow : 
docker compose run --rm airflow-webserver airflow users create \
  --username admin \
  --firstname Maria \
  --lastname El \
  --role Admin \
  --email admin@example.com

#lancer les services 
docker compose up -d

#Accéder à l’interface web Airflow

URL : http://localhost:8091

sudo chmod 666 /var/run/docker.sock
mkdir -p ./spark/checkpoints
