version: "3.8"

services:
  broker:
    image: apache/kafka:latest
    container_name: broker
    ports:
      - "9092:9092"  # Mappe le ports 9092 du conteneur au port 9092 de la machine hÃ´te
      - "9093:9093"  # AccÃ¨s EXTERNE pour votre script Python local
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller # joue le role de broker et listener au meme temps
      # KAFKA_LISTENERS dÃ©finit les ports que Kafka ouvre rÃ©ellement.
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9093,CONTROLLER://0.0.0.0:9094 # Internal : services dans le mÃªme Docker network, External : Clients hors Docker comme ton PC, CONTROLLER : communication entre les noeuds qui joue role de Controller
      # DÃ©finit comment les clients (consumers,producers)
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker:9092,EXTERNAL://localhost:9093
      
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
    volumes:
      - kafka_data:/var/lib/kafka/data

  cassandra:
      image: cassandra:latest
      container_name: cassandra
      ports:
        - "9042:9042"
      environment:
        - CASSANDRA_CLUSTER_NAME=RedditCluster
        - CASSANDRA_DC=datacenter1
        - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      volumes:
        - cassandra_data:/var/lib/cassandra
      healthcheck:
        test: ["CMD-SHELL", "[ $$(nodetool statusgossip) = running ]"]
        interval: 30s
        timeout: 10s
        retries: 5

  # ---  SERVICE D'INITIALISATION ---
  cassandra-init:
    image: cassandra:latest
    container_name: cassandra-init
    depends_on:
      - cassandra
    volumes:
      - ./init.cql:/init.cql  # On monte le fichier SQL dans le conteneur
    command: >
      bash -c "echo 'â³ Attente de Cassandra...' &&
      while ! cqlsh cassandra 9042 -e 'DESCRIBE KEYSPACES' > /dev/null 2>&1; do sleep 5; done &&
      echo 'âœ… Cassandra est prÃªt ! CrÃ©ation des tables...' &&
      cqlsh cassandra 9042 -f /init.cql &&
      echo 'ğŸ‰ Tables crÃ©Ã©es avec succÃ¨s !'"

  spark-master:
    build:
      context: .
      dockerfile: Dockerfile
    image: custom-spark:3.5.1
    container_name: spark-master
    environment:
      SPARK_MODE: master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master"] # commande executer a chaque fois que le conteneur dÃ©marre
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark:/opt/spark/work-dir
      - ./models:/opt/spark/models
    depends_on:
      - broker
      - cassandra

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: custom-spark:3.5.1
    container_name: spark-worker
    environment:
      SPARK_MODE: worker
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    ports:
      - "8081:8081"
    volumes:
      - ./spark:/opt/spark/work-dir
      - ./models:/opt/spark/models
    depends_on:
      - spark-master
      - cassandra
  
  sentiment-api:
    build:
      context: ./distilbert_fin
      dockerfile: Dockerfile
    container_name: sentiment-container
    image: sentiment-api:latest
    ports:
      - "8000:8000"

volumes:
  kafka_data:
  cassandra_data: