# Fichier: reddit_to_kafka_pipeline.py

import praw
import time
import json
from kafka.admin import KafkaAdminClient, NewTopic
from kafka import KafkaProducer
from kafka.errors import TopicAlreadyExistsError, NoBrokersAvailable

# =============================================================================
# ---                      PARTIE 1: CONFIGURATION                          ---
# =============================================================================

# --- Param√®tres Kafka ---
KAFKA_BROKER_URL = 'localhost:9092'
KAFKA_TOPIC = 'reddit-comments'
PARTITIONS = 3
REPLICATION_FACTOR = 1  # Doit √™tre 1 car nous n'avons qu'un seul broker

# --- Param√®tres Reddit (remplacez par vos propres identifiants) ---
# Vous devez obtenir ces informations en cr√©ant une application sur Reddit
CLIENT_ID = "VOTRE_CLIENT_ID"
CLIENT_SECRET = "VOTRE_CLIENT_SECRET"
USER_AGENT = "Pipeline de donn√©es v1.0 par u/VOTRE_NOM_UTILISATEUR"

# --- Param√®tres de recherche pour la Coupe du Monde F√©minine 2025 ---
SUBREDDITS_A_ECOUTER = "WomensSoccer+USWNT+NWSL+soccer+fussball"
MOTS_CLES = [
    "usa", "uswnt", "germany", "deutschland", "allemagne", "dfb frauen", 
    "goal", "tor", "penalty", "finale", "world cup"
]

# =============================================================================
# ---                   PARTIE 2: FONCTIONS UTILITAIRES                     ---
# =============================================================================

def create_kafka_topic():
    """
    Se connecte √† Kafka et s'assure que le topic existe.
    C'est la premi√®re √©tape avant de lancer le producteur.
    """
    print("--- √âtape 1: V√©rification du topic Kafka ---")
    try:
        admin_client = KafkaAdminClient(
            bootstrap_servers=KAFKA_BROKER_URL,
            client_id='topic_setup_client'
        )
        print("‚úÖ Connexion admin √† Kafka r√©ussie !")

        topic = NewTopic(
            name=KAFKA_TOPIC,
            num_partitions=PARTITIONS,
            replication_factor=REPLICATION_FACTOR
        )
        admin_client.create_topics(new_topics=[topic], validate_only=False)
        print(f"üéâ Topic '{KAFKA_TOPIC}' cr√©√© avec succ√®s !")
        admin_client.close()

    except TopicAlreadyExistsError:
        print(f"üëç Le topic '{KAFKA_TOPIC}' existe d√©j√†. Aucune action n'est n√©cessaire.")
        admin_client.close()
    except NoBrokersAvailable:
        print(f"‚ùå ERREUR : Impossible de se connecter au broker Kafka √† l'adresse {KAFKA_BROKER_URL}.")
        print("   Veuillez vous assurer que le conteneur Docker Kafka est bien en cours d'ex√©cution.")
        return False
    except Exception as e:
        print(f"Une erreur inattendue est survenue lors de la cr√©ation du topic : {e}")
        return False
    
    return True

def create_kafka_producer():
    """
    Cr√©e et retourne un producteur Kafka, pr√™t √† envoyer des messages.
    """
    print("\n--- √âtape 2: D√©marrage du producteur Kafka ---")
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BROKER_URL,
            # S√©rialise les messages en format JSON puis les encode en bytes
            value_serializer=lambda v: json.dumps(v).encode('utf-8')
        )
        print("‚úÖ Producteur Kafka connect√© et pr√™t !")
        return producer
    except NoBrokersAvailable:
        print("‚ùå ERREUR : Impossible de cr√©er le producteur. Broker non disponible.")
        return None
    except Exception as e:
        print(f"Une erreur inattendue est survenue lors de la cr√©ation du producteur : {e}")
        return None

def stream_reddit_comments(producer):
    """
    Se connecte √† Reddit, √©coute les nouveaux commentaires en temps r√©el
    et les envoie √† Kafka via le producteur fourni.
    """
    print("\n--- √âtape 3: Lancement du streaming Reddit ---")
    try:
        reddit = praw.Reddit(
            client_id=CLIENT_ID,
            client_secret=CLIENT_SECRET,
            user_agent=USER_AGENT
        )
        print(f"‚úÖ Connect√© √† Reddit en tant que {reddit.user.me()}")
        print(f"üì° √âcoute des nouveaux commentaires sur : r/{SUBREDDITS_A_ECOUTER.replace('+', ', r/')}")

        for comment in reddit.subreddit(SUBREDDITS_A_ECOUTER).stream.comments(skip_existing=True):
            # V√©rifie si le commentaire contient un mot-cl√© pertinent
            if any(keyword in comment.body.lower() for keyword in MOTS_CLES):
                data = {
                    "id": comment.id,
                    "author": str(comment.author),
                    "subreddit": str(comment.subreddit),
                    "text": comment.body,
                    "timestamp_utc": comment.created_utc,
                }
                
                print(f"üí¨ [Commentaire pertinent trouv√©] -> Envoi √† Kafka...")
                # Envoi des donn√©es au topic Kafka
                producer.send(KAFKA_TOPIC, value=data)
                
    except KeyboardInterrupt:
        print("\nüõë Arr√™t du streaming demand√© par l'utilisateur (Ctrl+C).")
    except Exception as e:
        print(f"‚ö†Ô∏è Une erreur critique est survenue dans le stream Reddit : {e}")

# =============================================================================
# ---                       PARTIE 3: POINT D'ENTR√âE                        ---
# =============================================================================

if __name__ == "__main__":
    # √âtape 1: S'assurer que le topic existe. Si √ßa √©choue, on arr√™te tout.
    if create_kafka_topic():
        
        # √âtape 2: Cr√©er le producteur Kafka.
        kafka_producer = create_kafka_producer()
        
        # √âtape 3: Si le producteur est bien cr√©√©, on lance le stream.
        if kafka_producer:
            stream_reddit_comments(kafka_producer)
            
            # Nettoyage √† la fin du script
            print("Fermeture du producteur Kafka...")
            kafka_producer.close()
            print("Producteur ferm√©. Au revoir !")
        else:
            print("Le script ne peut pas continuer car le producteur Kafka n'a pas pu √™tre cr√©√©.")