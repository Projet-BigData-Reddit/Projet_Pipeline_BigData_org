import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))
import praw
import time
import json
import re
from typing import List  
from kafka.admin import KafkaAdminClient, NewTopic
from kafka import KafkaProducer
from kafka.errors import  NoBrokersAvailable
from config import CLIENT_ID,CLIENT_SECRET, KEYWORDS, SUBREDDITS,USER_AGENT,USERNAME,KAFKA_TOPIC,KAFKA_BROKER_URL,PARTITIONS,REPLICATION_FACTOR
from utils import contains_keywords

class DataIngestion:
    """
    Classe responsable de l'ingestion de donn√©es Reddit et de leur envoi vers Kafka (streaming temps r√©el).
    """

    def __init__(self, client_id, client_secret, user_agent,
                 kafka_topic, kafka_broker_url,
                 partitions=1, replication_factor=1):

        self.kafka_topic = kafka_topic
        self.kafka_broker_url = kafka_broker_url
        self.partitions = partitions
        self.replication_factor = replication_factor

        # üîπ Connexion Reddit
        self.reddit = praw.Reddit(
            client_id=client_id,
            client_secret=client_secret,
            user_agent=user_agent
        )
        self.create_kafka_topic()
        self.producer = self.create_kafka_producer()

        print("‚úÖ Initialisation compl√®te : Reddit ‚Üí Kafka pr√™te.")


    # ==============================================================
    # M√âTHODES KAFKA
    # ==============================================================

    def create_kafka_topic(self):
        """Cr√©e le topic Kafka s'il n'existe pas d√©j√†."""
        try:
            admin_client = KafkaAdminClient(
                bootstrap_servers=self.kafka_broker_url,
                client_id='topic_setup_client'
            )

            existing_topics = admin_client.list_topics()

            if self.kafka_topic in existing_topics:
                print(f"üëç Le topic '{self.kafka_topic}' existe d√©j√†, aucune action n√©cessaire.")
            else:
                topic = NewTopic(
                    name=self.kafka_topic,
                    num_partitions=self.partitions,
                    replication_factor=self.replication_factor
                )
                admin_client.create_topics(new_topics=[topic], validate_only=False)
                print(f"üéâ Topic '{self.kafka_topic}' cr√©√© avec succ√®s !")

        except NoBrokersAvailable:
            print("‚ùå Aucun broker Kafka disponible. V√©rifie que ton serveur Kafka est en ligne.")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la cr√©ation du topic Kafka : {e}")
        finally:
            try:
                admin_client.close()
            except Exception:
                pass


    def create_kafka_producer(self):
        """Cr√©e un producteur Kafka."""
        try:
            producer = KafkaProducer(
                bootstrap_servers=self.kafka_broker_url,
                value_serializer=lambda v: json.dumps(v).encode('utf-8')
            )
            print("‚úÖ Producteur Kafka initialis√©.")
            return producer
        except Exception as e:
            print(f"Erreur cr√©ation producteur Kafka : {e}")
            return None


    def send_to_kafka(self, data):
        """Envoie un message JSON vers Kafka."""
        if not self.producer:
            print("‚ö†Ô∏è Producteur Kafka non initialis√©.")
            return
        try:
            self.producer.send(self.kafka_topic, value=data)
            print(data)
            self.producer.flush() 
            print(f"üì§ Envoy√© sur Kafka : {data['id']} ({data['subreddit']})")
        except Exception as e:
            print(f"Erreur envoi Kafka : {e}")


    # ==============================================================
    # REDDIT STREAMING
    # ==============================================================

    def is_relevant(self, text, keywords):
        """V√©rifie si un texte contient au moins un mot-cl√© pertinent."""
        return contains_keywords(text,keywords)


    def stream_reddit_comments(self, subreddits: str, keywords: List[str]):
        """Stream en temps r√©el des commentaires Reddit vers Kafka."""
        print(f"üì° D√©marrage du streaming Reddit ‚Üí Kafka sur '{self.kafka_topic}'...")
        try:
            for comment in self.reddit.subreddit(subreddits).stream.comments(skip_existing=True):
                if self.is_relevant(comment.body, keywords):
                    data = {
                        "id": comment.id,
                        "author": str(comment.author),
                        "subreddit": str(comment.subreddit),
                        "text": comment.body,
                        "timestamp": comment.created_utc,
                        "score": comment.score
                    }
                    self.send_to_kafka(data)
        except KeyboardInterrupt:
            print("üõë Stream interrompu manuellement (Ctrl+C).")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur stream Reddit : {e}")
            time.sleep(5)

if __name__ == "__main__":

    ingestion = DataIngestion(
        CLIENT_ID, CLIENT_SECRET, USER_AGENT,
        KAFKA_TOPIC, KAFKA_BROKER_URL
    )

    ingestion.stream_reddit_comments(SUBREDDITS, KEYWORDS)